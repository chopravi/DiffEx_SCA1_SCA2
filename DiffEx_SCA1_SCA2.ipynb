{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared Gene Dysregulation in Multiple SCA Models\n",
    "========================\n",
    "This notebook takes .csv notebooks containing lists of dysregulated genes and their gene expression changes (relative to WT), and seeks to determine what genes are dysregulated across multiple models of ataxia\n",
    "\n",
    "\n",
    "Written by Ravi Chopra (chopra.r@wustl.edu) and John Cooper (jpcoope@utexas.edu)<br>\n",
    "Last commit: 5/18/2020<br>\n",
    "Python version: Python 3.6.3<br>\n",
    "Modules: pandas 1.0.3, numpy 1.13.3, scipy 0.19.1, matplotlib 2.1.0, upsetplot 0.4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from upsetplot import plot, from_memberships, from_contents\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    \n",
    "    \"\"\" Return a cleaned dataframe with NaN rows removed and duplicate\n",
    "        fold change measurements averaged \"\"\"\n",
    "    \n",
    "    # Select all rows from the df that don't have NA\n",
    "    clean_df = df.loc[df['Gene name'].notnull(), :]\n",
    "    # Select only rows with Gene names that are duplicated\n",
    "    dup_df = clean_df[clean_df.duplicated(subset='Gene name',keep=False)]\n",
    "    dup_df = dup_df.sort_values(by=['Gene name'])\n",
    "    try: # won't work if no duplicates to average\n",
    "        # Average duplicate fold change measurements\n",
    "        dup_df = dup_df.groupby('Gene name',as_index=False).mean()\n",
    "        dup_df = dup_df.round(3)\n",
    "    except:\n",
    "        print(f'No duplicated gene names in dataset for df with column 1: {df.columns[1]}')\n",
    "        pass\n",
    "    # Drop rows from the original dataframe that are in the duplicate df\n",
    "    cond = clean_df['Gene name'].isin(dup_df['Gene name'])\n",
    "    clean_df.drop(clean_df[cond].index, inplace = True)\n",
    "    clean_df = clean_df.append(dup_df)\n",
    "    clean_df = clean_df.reset_index(drop=True)\n",
    "    \n",
    "    del dup_df\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_combinations(names_list, k):\n",
    "    \n",
    "    \"\"\" Return a list of unique combinations (each element is a tuple)\n",
    "        from the names_list \"\"\"\n",
    "    \n",
    "    return list(combinations(names_list, k))\n",
    "\n",
    "def find_pairwise_overlaps(dfs_dict):\n",
    "    \n",
    "    \"\"\" Return a dataframe with a column holding the overlapping\n",
    "        set of 'Gene name's for each unique pair of models in the\n",
    "        dfs_dict \"\"\"\n",
    "\n",
    "    model_pairs = get_combinations(names_list=list(dfs_dict.keys()), k=2)\n",
    "    overlaps_dict = {}\n",
    "    \n",
    "    for combi_tuple in model_pairs:\n",
    "        # create a name to be used for this combination's \n",
    "        # dataframe column\n",
    "        combi_name = '-'.join(combi_tuple)\n",
    "        # find overlap between the two model gene name columns\n",
    "        df_1 = dfs_dict[combi_tuple[0]]\n",
    "        df_2 = dfs_dict[combi_tuple[1]]\n",
    "        overlap_df = pd.merge(df_1, df_2, on='Gene name')\n",
    "\n",
    "        overlaps_dict[combi_name] = overlap_df['Gene name']        \n",
    "        \n",
    "    overlaps_df = pd.DataFrame(overlaps_dict)\n",
    "    return overlaps_df\n",
    "    \n",
    "def find_triplet_overlaps(dfs_dict):\n",
    "    \n",
    "    \"\"\" Return a dataframe with a column holding the overlapping\n",
    "        set of 'Gene name's for each unique unique group of three \n",
    "        models in the dfs_dict \"\"\"\n",
    "\n",
    "    model_trips = get_combinations(names_list=list(dfs_dict.keys()), k=3)\n",
    "    overlaps_dict = {}\n",
    "    \n",
    "    for combi_tuple in model_trips:\n",
    "        # create a name to be used for this combination's \n",
    "        # dataframe column\n",
    "        combi_name = '-'.join(combi_tuple)\n",
    "        # find overlap between the two model gene name columns\n",
    "        df_1 = dfs_dict[combi_tuple[0]]\n",
    "        df_2 = dfs_dict[combi_tuple[1]]\n",
    "        df_3 = dfs_dict[combi_tuple[2]]\n",
    "        \n",
    "        overlap_df = pd.merge(df_1, df_2, on='Gene name')\n",
    "        overlap_df = pd.merge(overlap_df, df_3, on='Gene name')\n",
    "\n",
    "        overlaps_dict[combi_name] = overlap_df['Gene name']        \n",
    "        \n",
    "    overlaps_df = pd.DataFrame(overlaps_dict)\n",
    "    \n",
    "    return overlaps_df\n",
    "\n",
    "def find_quad_overlaps(dfs_dict):\n",
    "    \n",
    "    \"\"\" Return a dataframe with a column holding the overlapping\n",
    "        set of 'Gene name's across all models in dfs_dict \"\"\"\n",
    "\n",
    "    model_trips = get_combinations(names_list=list(dfs_dict.keys()), k=4)\n",
    "    overlaps_dict = {}\n",
    "    \n",
    "    for combi_tuple in model_trips:\n",
    "        # create a name to be used for this combination's \n",
    "        # dataframe column\n",
    "        combi_name = '-'.join(combi_tuple)\n",
    "        # find overlap between the two model gene name columns\n",
    "        df_1 = dfs_dict[combi_tuple[0]]\n",
    "        df_2 = dfs_dict[combi_tuple[1]]\n",
    "        df_3 = dfs_dict[combi_tuple[2]]\n",
    "        df_4 = dfs_dict[combi_tuple[3]]\n",
    "        \n",
    "        overlap_df = pd.merge(df_1, df_2, on='Gene name')\n",
    "        overlap_df = pd.merge(overlap_df, df_3, on='Gene name')\n",
    "        overlap_df = pd.merge(overlap_df, df_4, on='Gene name')\n",
    "\n",
    "        overlaps_dict[combi_name] = overlap_df['Gene name']        \n",
    "        \n",
    "    overlaps_df = pd.DataFrame(overlaps_dict)\n",
    "    \n",
    "    return overlaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hypergeometric_test(dfs_dict):\n",
    "    \n",
    "    \"\"\" Return nothing. Run a hypergeometric test to determine \n",
    "        significance of overlaps between dysregulated channels in\n",
    "        each pair of models in dfs_dict. Print p-values for likelihood\n",
    "        of channel overlap between each unique pair of models. \"\"\"\n",
    "    \n",
    "    pairwise_overlaps_df = find_pairwise_overlaps(dfs_dict)\n",
    "\n",
    "    for pair_name in pairwise_overlaps_df.columns:\n",
    "        # Define total number of genes and channels overlapping between current two models\n",
    "        overlapping_genes = pairwise_overlaps_df.loc[:, pair_name].dropna()\n",
    "        overlapping_channels = pd.Series(list(set(overlapping_genes).intersection(set(IUPHAR_Channels_names))))\n",
    "        total_channel_overlaps = len(overlapping_channels)\n",
    "\n",
    "        # Define the total number of channels in the IUPHAR channel database\n",
    "        IUPHAR_chan_num = len(IUPHAR_Channels_names)\n",
    "\n",
    "        # Find the names of the two models under consideration\n",
    "        overlap_model_names = pair_name.split('-')\n",
    "\n",
    "        # Find the total number of channels dysregulated in each model's dataset\n",
    "        model_1_genes = dfs_dict[overlap_model_names[0]].loc[:, 'Gene name']\n",
    "        model_1_channels = pd.Series(list(set(model_1_genes).intersection(set(IUPHAR_Channels_names))))\n",
    "        total_model_1_channels = len(model_1_channels)\n",
    "\n",
    "        model_2_genes = dfs_dict[overlap_model_names[1]].loc[:, 'Gene name']\n",
    "        model_2_channels = pd.Series(list(set(model_2_genes).intersection(set(IUPHAR_Channels_names))))\n",
    "        total_model_2_channels = len(model_2_channels)\n",
    "\n",
    "        pairwise_overlap_p_value = 1-stats.hypergeom.cdf(total_channel_overlaps,\n",
    "                                                         IUPHAR_chan_num,\n",
    "                                                         total_model_1_channels,\n",
    "                                                         total_model_2_channels)\n",
    "\n",
    "        print(f'{overlap_model_names[0]} and {overlap_model_names[1]} p-value={pairwise_overlap_p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_channels_dict(dfs_dict):\n",
    "    \n",
    "    \"\"\" Return a dict holding the number of \n",
    "        channels dysregulated in each model \"\"\"\n",
    "    \n",
    "    n_channels_dict = {}\n",
    "    \n",
    "    for model_name, model_df in dfs_dict.items():\n",
    "        \n",
    "        gene_names = model_df.loc[:, 'Gene name']\n",
    "        channel_names = pd.Series(list(set(gene_names).intersection(set(IUPHAR_Channels_names))))\n",
    "        n_channels = len(channel_names)\n",
    "        \n",
    "        n_channels_dict[model_name] = n_channels\n",
    "        \n",
    "    return n_channels_dict\n",
    "\n",
    "def set_channels_df(dfs_dict, filename):\n",
    "    # Save and get a csv with each model as column and its respective\n",
    "    # list of dysregulated channels along rows\n",
    "    \n",
    "    model_channels_df_dict = {}\n",
    "    for model_name, model_df in dfs_dict.items():\n",
    "        \n",
    "        gene_names = model_df.loc[:, 'Gene name']\n",
    "        channel_names = pd.Series(list(set(gene_names).intersection(set(IUPHAR_Channels_names))))\n",
    "        model_channels_df_dict[model_name] = channel_names\n",
    "    \n",
    "    model_channels_df = pd.DataFrame(model_channels_df_dict)\n",
    "    if filename:\n",
    "        model_channels_df.to_csv(filename)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return model_channels_df, model_channels_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_channel_dfs(dfs_dict, n_channels_dict):\n",
    "    \n",
    "    \"\"\" Return a dict of dataframes simulated according to the data\n",
    "        in dfs_dict. For each model, choose a random set of n channels\n",
    "        from the IUHPAR database where n = number of channels dysregulated\n",
    "        in that model. n is defined in n_channels_dict \"\"\"\n",
    "    \n",
    "    # for each model, choose a random set of of channels from IUPHAR database\n",
    "    # of size however meany channels are in that models original data    \n",
    "    sim_dfs_dict = {}\n",
    "\n",
    "    for model_name, model_df in dfs_dict.items():\n",
    "        # get the number of channels dysregulated in this model\n",
    "        n_channels = n_channels_dict[model_name]\n",
    "        # Sample the IUPHAR channels and make a simulated dataframe\n",
    "        # for this model's dysregulated Genes\n",
    "        sim_channel_names = IUPHAR_Channels_names.sample(n_channels)\n",
    "        sim_model_df = pd.DataFrame({'Gene name': sim_channel_names})\n",
    "\n",
    "        # Add this simulated model df to the sim_dfs_dict\n",
    "        sim_dfs_dict[model_name] = sim_model_df\n",
    "        \n",
    "    return sim_dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_triplet_overlaps(dfs_dict, n_runs, observed_overlap_n, n_channels_dict):\n",
    "    \n",
    "    \"\"\" Return a tuple: (triplet_overlaps, n_succeses) where triplet_overlaps is a\n",
    "        list of total overlaps found for each simulation of length n_runs and\n",
    "        n_successes is the number of runs with >= observed_overlap_n simulated\n",
    "        overlaps. \"\"\"\n",
    "    \n",
    "    triplet_overlaps = []\n",
    "    n_successes = 0\n",
    "    \n",
    "    for i in range(0, n_runs):\n",
    "        \n",
    "        # Simulate a dictionary of dataframes, one dataframe\n",
    "        # for each model\n",
    "        sim_channel_dfs_dict = simulate_channel_dfs(dfs_dict, n_channels_dict)\n",
    "        sim_triplet_overlaps_df = find_triplet_overlaps(sim_channel_dfs_dict)\n",
    "        triplet_overlaps_list = [sim_triplet_overlaps_df.loc[:, column].dropna() for column in sim_triplet_overlaps_df.columns]\n",
    "        triplet_overlaps_names = pd.concat(triplet_overlaps_list).unique() # returns a series object\n",
    "        \n",
    "        triplet_overlaps_num = len(triplet_overlaps_names)\n",
    "        print(f'Run number {i+1} of {n_runs}. Found {triplet_overlaps_num} triple overlapping channels',\n",
    "              end='\\r')\n",
    "        \n",
    "        triplet_overlaps.append(triplet_overlaps_num)\n",
    "        \n",
    "        if triplet_overlaps_num >= observed_overlap_n:\n",
    "            n_successes += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return triplet_overlaps, n_successes\n",
    "\n",
    "def simulate_quad_overlaps(dfs_dict, n_runs, observed_overlap_n, n_channels_dict):\n",
    "    \n",
    "    \"\"\" Return a tuple: (quad_overlaps, n_succeses) where quad_overlaps is a\n",
    "        list of total overlaps found for each simulation of length n_runs and\n",
    "        n_successes is the number of runs with >= observed_overlap_n simulated\n",
    "        overlaps. \"\"\"\n",
    "    \n",
    "    quad_overlaps = []\n",
    "    n_successes = 0\n",
    "    \n",
    "    for i in range(0, n_runs):\n",
    "        \n",
    "        # Simulate a dictionary of dataframes, one dataframe\n",
    "        # for each model\n",
    "        sim_channel_dfs_dict = simulate_channel_dfs(dfs_dict, n_channels_dict)\n",
    "        sim_quad_overlaps_df = find_quad_overlaps(sim_channel_dfs_dict)\n",
    "        quad_overlaps_list = [sim_quad_overlaps_df.loc[:, column].dropna() for column in sim_quad_overlaps_df.columns]\n",
    "        quad_overlaps_names = pd.concat(quad_overlaps_list).unique() # returns a series object\n",
    "        \n",
    "        quad_overlaps_num = len(quad_overlaps_names)\n",
    "        print(f'Run number {i+1} of {n_runs}. Found {quad_overlaps_num} quad overlapping channels',\n",
    "              end='\\r')\n",
    "        \n",
    "        quad_overlaps.append(quad_overlaps_num)\n",
    "        \n",
    "        if quad_overlaps_num >= observed_overlap_n:\n",
    "            n_successes += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return quad_overlaps, n_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_non_channels(overlaps_df, filename):    \n",
    "    \n",
    "    \"\"\" Return the overlap dataframe with all channels dropped\n",
    "        and index reset. Save the df as a csv with the filename\n",
    "        passed this function. \"\"\"\n",
    "    \n",
    "    df = overlaps_df\n",
    "    \n",
    "    channels_df_dict = {}\n",
    "    for column in df.columns:\n",
    "        # For each set of overlaps, drop all the gene names that are not\n",
    "        # channels. They are replaced by NaNs.\n",
    "        channels_bool = df.loc[:, column].isin(IUPHAR_Channels_names)\n",
    "        channels_df_dict[column] = df.loc[channels_bool, column]\n",
    "\n",
    "    channels_df = pd.DataFrame(channels_df_dict)\n",
    "    \n",
    "    clean_channels_df = channels_df.reset_index(drop=True).copy()    \n",
    "    for column in channels_df.columns:\n",
    "        # Set all of the rows in this column to NaN so they can be replaced\n",
    "        # by lists of channel names in each overlap.\n",
    "        clean_channels_df.loc[:, column] = np.NaN\n",
    "        channel_names = list(channels_df.loc[:, column].dropna())\n",
    "        # Put the list of channels in the overlap's row. Save the df\n",
    "        clean_channels_df.loc[0:len(channel_names)-1, column] = channel_names\n",
    "        clean_channels_df.to_csv(filename)\n",
    "        \n",
    "    return clean_channels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in in data, set number of runs for overlap simulation, and set dfs and model_names lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Import gene expression data from ataxia mouse models to pandas dataframes\n",
    "#Gene expression data sources are outlined the methods section. In all cases, raw data tables were modified so that .csv files\n",
    "#below have 3 columns: \n",
    "#column 1 - dysregulated gene names\n",
    "#column 2 - log2 transformation of the fold expression for gene in mouse model of interest relative to appropriate WT\n",
    "#column 3 - fold expression for gene in mouse model of interest relative to appropriate WT\n",
    "\n",
    "ATXN1_82Q_5_Wk = pd.read_csv('ATXN1_82Q_5_Week.csv')\n",
    "ATXN1_154Q_5_12_Wk = pd.read_csv('ATXN1_154Q_5_12_Week.csv')\n",
    "ATXN2_127Q_6_Wk = pd.read_csv('ATXN2_127Q_6_Week.csv')\n",
    "ATXN2_72Q_8_Wk = pd.read_csv('ATXN2_72Q_8_Week.csv')\n",
    "\n",
    "#Import a list of all ion channel genes found in mice\n",
    "IUPHAR_Channels = pd.read_csv('IUPHAR_Channels.csv', encoding = \"ANSI\", engine='python')\n",
    "IUPHAR_Channels_names = IUPHAR_Channels['Gene name']\n",
    "\n",
    "_n_runs = 1000\n",
    "\n",
    "# Set up lists for making dictionary below\n",
    "dfs = [ATXN1_82Q_5_Wk,\n",
    "       ATXN1_154Q_5_12_Wk,\n",
    "       ATXN2_127Q_6_Wk,\n",
    "       ATXN2_72Q_8_Wk]\n",
    "\n",
    "model_names = ['ATXN1_82Q_5_Wk',\n",
    "               'ATXN1_154Q_5_12_Wk',\n",
    "               'ATXN2_127Q_6_Wk',\n",
    "               'ATXN2_72Q_8_Wk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean the dataframes read in above and save them as .csvs. Put them into a dictionary called dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicated gene names in dataset for df with column 1: Log2(Fold expression) (ATXN1[82Q] vs. WT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Chopra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Clean the dfs\n",
    "clean_dfs = []\n",
    "for df in dfs:\n",
    "    clean_dfs.append(clean_dataframe(df))\n",
    "    \n",
    "# Save the cleaned dfs\n",
    "i = 0\n",
    "for df in clean_dfs:\n",
    "    name = model_names[i]\n",
    "    df.to_csv(f'{name}_cleaned.csv')\n",
    "    i += 1\n",
    "    \n",
    "dfs_dict = dict(zip(model_names, clean_dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a dataframe and dictionary to store dysregulated channels in each model and save the dataframe as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dysreg_channels_df, channels_dict = set_channels_df(dfs_dict, 'channels_dysreg_in_each_model.csv')\n",
    "# this saves a .csv with each column a different model each row its dysregulated channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a 'contents' data structure from the dictionary above and plot overlap distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot singlet overlaps and up. Note with the data in this form (constructed with from_contents()), the function is not plotting overlaps with 0 genes in overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Genes in Overlap')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename keys for aesthetic purposes\n",
    "keys = ['ATXN1[82Q]',\n",
    "        'Atxn1(154Q)',\n",
    "        'ATXN2[Q127]',\n",
    "        'ATXN2-BAC-Q72']\n",
    "\n",
    "channels_dict = dict(zip(keys, channels_dict.values()))\n",
    "\n",
    "contents = from_contents(channels_dict)\n",
    "\n",
    "plot_dict = plot(contents)\n",
    "\n",
    "plot_dict['intersections'].set_ylim(0, 50)\n",
    "plot_dict['intersections'].set_ylabel('Genes in Overlap', fontsize=12)\n",
    "\n",
    "plt.savefig('python_upset_with_singlet_overlaps.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot pairwise overlaps and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Genes in Overlap')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3.5, 12.875)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_dict = plot(contents)\n",
    "\n",
    "#plot_dict['totals'].set_xlim(50, 0)\n",
    "\n",
    "plot_dict['intersections'].set_ylim(0, 10)\n",
    "plot_dict['intersections'].set_ylabel('Genes in Overlap', fontsize=12)\n",
    "plot_dict['intersections'].set_xlim(3.5, 12.875)\n",
    "\n",
    "plt.savefig('python_upset_pairwise_and_up.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find pairwise overlaps and analyze overlap significance with hypergeometric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise_overlaps_df = find_pairwise_overlaps(dfs_dict)\n",
    "pairwise_overlaps_df.to_csv('pairwise_all_genes_overlaps.csv')\n",
    "pairwise_channels_overlaps = drop_non_channels(pairwise_overlaps_df,\n",
    "                                              'pairwise_channels_overlaps.csv')\n",
    "pairwise_overlaps_list = [pairwise_overlaps_df.loc[:, column].dropna() for column in pairwise_overlaps_df.columns]\n",
    "pairwise_overlaps_names = pd.concat(pairwise_overlaps_list).unique()\n",
    "\n",
    "pairwise_overlaps_channels = pd.Series(list(set(pairwise_overlaps_names).intersection(set(IUPHAR_Channels_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATXN1_82Q_5_Wk and ATXN1_154Q_5_12_Wk p-value=0.028727814921322814\n",
      "ATXN1_82Q_5_Wk and ATXN2_127Q_6_Wk p-value=0.0005124345063888258\n",
      "ATXN1_82Q_5_Wk and ATXN2_72Q_8_Wk p-value=0.014406874471300068\n",
      "ATXN1_154Q_5_12_Wk and ATXN2_127Q_6_Wk p-value=0.0002980442903435243\n",
      "ATXN1_154Q_5_12_Wk and ATXN2_72Q_8_Wk p-value=0.0005893463610623373\n",
      "ATXN2_127Q_6_Wk and ATXN2_72Q_8_Wk p-value=0.0027472618229910095\n"
     ]
    }
   ],
   "source": [
    "hypergeometric_test(dfs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find all channels that are dysregulated in 3 or more models and simulate random channel selections to see if similar overlaps to those observed occur by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of channels dysregulated in any 3 models = 12\n"
     ]
    }
   ],
   "source": [
    "# Find the set of all genes that are shared in 3 or more models\n",
    "triplet_overlaps_df = find_triplet_overlaps(dfs_dict)\n",
    "triplet_overlaps_df.to_csv('triplet_all_genes_overlaps_df.csv')\n",
    "triplet_channels_overlaps = drop_non_channels(triplet_overlaps_df,\n",
    "                                              'triplet_channels_overlaps.csv')\n",
    "triplet_overlaps_list = [triplet_overlaps_df.loc[:, column].dropna() for column in triplet_overlaps_df.columns]\n",
    "triplet_overlaps_names = pd.concat(triplet_overlaps_list).unique() # returns a series object\n",
    "\n",
    "# Find the set of all channel genes that are shared in 3 or more models\n",
    "triplet_overlaps_channels = pd.Series(list(set(triplet_overlaps_names).intersection(set(IUPHAR_Channels_names))))\n",
    "triplet_overlaps_channels_num = len(triplet_overlaps_channels)\n",
    "print('Total number of channels dysregulated in any 3 models =', triplet_overlaps_channels_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of number of runs out of 1000 greater than/equal to 12 channel genes in overlap of any 3 models: 0\n",
      "p-value for greater than/equal to 20 channel genes in all intersections of 3 models: 0.0\n"
     ]
    }
   ],
   "source": [
    "n_channels_dict = get_n_channels_dict(dfs_dict)\n",
    "overlaps, count = simulate_triplet_overlaps(dfs_dict,\n",
    "                                            n_runs=_n_runs,\n",
    "                                            observed_overlap_n=triplet_overlaps_channels_num,\n",
    "                                            n_channels_dict=n_channels_dict)\n",
    "\n",
    "print('Count of number of runs out of', _n_runs, 'greater than/equal to', triplet_overlaps_channels_num, 'channel genes in overlap of any 3 models:', count)\n",
    "Three_sim_pvalue = count/_n_runs\n",
    "print('p-value for greater than/equal to 20 channel genes in all intersections of 3 models:', Three_sim_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find all channels that are dysregulated in all 4 models and simulate random channels selections to see if similar overlap to that observed occurs by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of channels dysregulated in all 4 models = 1\n"
     ]
    }
   ],
   "source": [
    "# Find the set of all genes that are shared in all 4 models\n",
    "quad_overlaps_df = find_quad_overlaps(dfs_dict)\n",
    "quad_overlaps_df.to_csv('quad_all_genes_overlaps_df.csv')\n",
    "quad_channels_overlaps = drop_non_channels(quad_overlaps_df,\n",
    "                                           'quad_channels_overlaps.csv')\n",
    "quad_overlaps_list = [quad_overlaps_df.loc[:, column].dropna() for column in quad_overlaps_df.columns]\n",
    "quad_overlaps_names = pd.concat(quad_overlaps_list).unique() # returns a series object\n",
    "\n",
    "# Find the set of all channel genes that are shared in 3 or more models\n",
    "quad_overlaps_channels = pd.Series(list(set(quad_overlaps_names).intersection(set(IUPHAR_Channels_names))))\n",
    "quad_overlaps_channels_num = len(quad_overlaps_channels)\n",
    "print('Total number of channels dysregulated in all 4 models =', quad_overlaps_channels_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of number of runs out of 1000 greater than/equal to 1 channel genes in overlap of all 4 models: 45\n",
      "p-value for greater than/equal to 20 channel genes in all intersections of 3 models: 0.045\n"
     ]
    }
   ],
   "source": [
    "n_channels_dict = get_n_channels_dict(dfs_dict)\n",
    "overlaps, count = simulate_quad_overlaps(dfs_dict,\n",
    "                                         n_runs=_n_runs,\n",
    "                                         observed_overlap_n=quad_overlaps_channels_num,\n",
    "                                         n_channels_dict=n_channels_dict)\n",
    "\n",
    "print('Count of number of runs out of', _n_runs, 'greater than/equal to', quad_overlaps_channels_num, 'channel genes in overlap of all 4 models:', count)\n",
    "Three_sim_pvalue = count/_n_runs\n",
    "print('p-value for greater than/equal to 20 channel genes in all intersections of 3 models:', Three_sim_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot all unique intersections between models for final figure. \n",
    "This requires some restructuring of the data produced above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate groups with every combination of models from size none to 4\n",
    "# Each group is a list of model names in that combination.\n",
    "groups = [[]]\n",
    "for k_size in range(1, 5):\n",
    "    \n",
    "    for combination in get_combinations(model_names, k_size):\n",
    "        groups.append(list(combination))\n",
    "\n",
    "# Define dysreg_channels_df, channels_dict without saving\n",
    "dysreg_channels_df, channels_dict = set_channels_df(dfs_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe where each column is one of every combination\n",
    "# of model names size none to 4 referring to the list of channels\n",
    "# dysregulated in the intersection of that combination\n",
    "master_overlaps_df = pd.concat([dysreg_channels_df,\n",
    "                                pairwise_channels_overlaps,\n",
    "                                triplet_channels_overlaps,\n",
    "                                quad_channels_overlaps], ignore_index=False, sort=False)\n",
    "# Other sets that are used in contrasts below. We need a list of all channels in the\n",
    "# IUPHAR channels database and a list of all the channels dysregulataed in any of the\n",
    "# models to create the none set\n",
    "all_channels_list = [master_overlaps_df.loc[:, column].dropna() for column in master_overlaps_df.columns]\n",
    "all_channels_names = pd.concat(all_channels_list).unique()\n",
    "IUPHAR_Channels_set = set(IUPHAR_Channels_names)\n",
    "none_set = IUPHAR_Channels_set.difference(all_channels_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the number of channels dysregulated uniquely in the\n",
    "# intersection of each combination of models from size none to 4.\n",
    "n_unique_channels_list = [len(none_set)]\n",
    "for i in range(1, len(groups)):    \n",
    "    \n",
    "    group = groups[i]    \n",
    "    if len(group) == 1:\n",
    "        key = group[0]\n",
    "        channels = master_overlaps_df[key].dropna()     \n",
    "        unique_names = set(channels).difference(set(pairwise_overlaps_names))\n",
    "        n_unique_channels_list.append(len(unique_names))\n",
    "\n",
    "    elif len(group) == 2:\n",
    "        key = '-'.join(group)\n",
    "        channels = master_overlaps_df[key].dropna()\n",
    "        unique_names = set(channels).difference(set(triplet_overlaps_names))\n",
    "        n_unique_channels_list.append(len(unique_names))\n",
    "        \n",
    "    elif len(group) == 3:\n",
    "        key = '-'.join(group)\n",
    "        channels = master_overlaps_df[key].dropna()\n",
    "        unique_names = set(channels).difference(set(quad_overlaps_names))\n",
    "        n_unique_channels_list.append(len(unique_names))\n",
    "        \n",
    "    elif len(group) == 4:\n",
    "        key = '-'.join(group)\n",
    "        channels = master_overlaps_df[key].dropna()\n",
    "        unique_names = channels\n",
    "        n_unique_channels_list.append(len(unique_names))        \n",
    "    else:\n",
    "        print(\"Too many groups in list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[164, 15, 4, 44, 13, 0, 7, 1, 3, 2, 5, 3, 0, 5, 3, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unique_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename keys for aesthetic purposes\n",
    "keys = ['ATXN1[82Q]',\n",
    "        'Atxn1(154Q)',\n",
    "        'ATXN2[Q127]',\n",
    "        'ATXN2-BAC-Q72']\n",
    "# Get every combination of models from size none to 4\n",
    "# from keys defined above. Used to label intersections\n",
    "# on x axis in plot below\n",
    "plot_groups = [[]]\n",
    "for k_size in range(1, 5):    \n",
    "    for combination in get_combinations(keys, k_size):\n",
    "        plot_groups.append(list(combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'IUPHAR Ion Channel Genes (Count)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_list = from_memberships(plot_groups[:], data=n_unique_channels_list[:])\n",
    "plot_dict = plot(plot_list)\n",
    "\n",
    "x_lim = ()\n",
    "y_lim = (0, 50)\n",
    "\n",
    "plot_dict['intersections'].set_ylim(y_lim[0], y_lim[1])\n",
    "plot_dict['intersections'].set_ylabel('IUPHAR Ion Channel Genes (Count)', fontsize=10)\n",
    "\n",
    "plt.savefig(f'Upset_all_groups_ylim({y_lim[0]},{y_lim[1]}).svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'IUPHAR Ion Channel Genes (Count)')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_list = from_memberships(plot_groups[:], data=n_unique_channels_list[:])\n",
    "plot_dict = plot(plot_list)\n",
    "\n",
    "x_lim = ()\n",
    "y_lim = (150, 200)\n",
    "\n",
    "plot_dict['intersections'].set_ylim(y_lim[0], y_lim[1])\n",
    "plot_dict['intersections'].set_ylabel('IUPHAR Ion Channel Genes (Count)', fontsize=10)\n",
    "\n",
    "plt.savefig(f'Upset_all_groups_ylim({y_lim[0]},{y_lim[1]}).svg', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
